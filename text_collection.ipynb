{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 爬取PTT的資料\n",
    "1. 輸入「要爬的網址」、「要爬的頁數」、「檔案名稱」\n",
    "2. 爬取PTT（作者, 看板, 標題, 日期, 內文, 推文數, 噓文數, 箭頭留言數, 連結, 留言資訊）\n",
    "3. 處理原始資料後，分別存成兩個csv檔：文章資料、留言資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬網頁的程式\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "# 設定headers\n",
    "headers = {\n",
    "    'cookie': 'over18=1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36'\n",
    "}\n",
    "\n",
    "# 爬取文章的詳細資訊\n",
    "def get_article_content(article_url):\n",
    "    response = requests.get(article_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    meta_values = soup.find_all('span', class_='article-meta-value')\n",
    "    if not meta_values:\n",
    "        return None\n",
    "\n",
    "    author, board, title, date = (meta.text for meta in meta_values)\n",
    "    content = soup.find(id=\"main-content\").text\n",
    "    content = content.split(date)[-1].split('※ 發信站: 批踢踢實業坊(ptt.cc)')[0].split('\\n', 1)[-1].rsplit('\\n', 1)[0]\n",
    "\n",
    "    # 爬取留言\n",
    "    comments = []\n",
    "    push_tags = soup.find_all('div', class_='push')\n",
    "    for push_tag in push_tags:\n",
    "        push_type = push_tag.find('span', class_='push-tag').text.strip()\n",
    "        push_user = push_tag.find('span', class_='push-userid').text.strip()\n",
    "        push_content = push_tag.find('span', class_='push-content').text.strip()[2:]\n",
    "        push_ipdatetime = push_tag.find('span', class_='push-ipdatetime').text.strip()\n",
    "        \n",
    "        comment = {\n",
    "            'type': push_type.strip(),\n",
    "            'user': push_user,\n",
    "            'content': push_content,\n",
    "            'ipdatetime': push_ipdatetime\n",
    "        }\n",
    "        \n",
    "        comments.append(comment)\n",
    "\n",
    "    return {\n",
    "        'author': author,\n",
    "        'board': board,\n",
    "        'title': title,\n",
    "        'date': date,\n",
    "        'content': content,\n",
    "        'comments': comments,\n",
    "        'link': article_url\n",
    "    }\n",
    "\n",
    "# 所有文章連結\n",
    "def get_articles_list(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return ['https://www.ptt.cc' + link.a['href'] for link in soup.find_all('div', class_='title') if link.a]\n",
    "\n",
    "# 主函式: 爬取多頁，存儲結果\n",
    "def main(url, pages, csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf_8_sig') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['作者', '看板', '標題', '日期', '內文', '推文數', '噓文數', '箭頭留言數', '連結', '留言資訊'])\n",
    "        \n",
    "    for _ in range(pages):\n",
    "        article_urls = get_articles_list(url)\n",
    "        for article_url in article_urls:\n",
    "            article_data = get_article_content(article_url)\n",
    "            if article_data:\n",
    "                # 初始化推文、噓文和箭頭留言的計數器\n",
    "                pushes = 0\n",
    "                boos = 0\n",
    "                arrows = 0\n",
    "                # 遍歷留言列表來計算推文、噓文和箭頭留言的數量\n",
    "                for comment in article_data['comments']:\n",
    "                    if comment['type'] == '推':\n",
    "                        pushes += 1\n",
    "                    elif comment['type'] == '噓':\n",
    "                        boos += 1\n",
    "                    elif comment['type'] == '→':\n",
    "                        arrows += 1\n",
    "                # 將留言資訊轉換成json\n",
    "                comments_json = json.dumps(article_data['comments'], ensure_ascii=False)\n",
    "                with open(csv_file_path, 'a', newline='', encoding='utf_8_sig') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([article_data['author'], article_data['board'], article_data['title'], article_data['date'], article_data['content'], pushes, boos, arrows, article_data['link'], comments_json])\n",
    "            time.sleep(0.5)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        next_page = 'https://www.ptt.cc' + soup.find('a', string='‹ 上頁')['href']\n",
    "        url = next_page\n",
    "\n",
    "\n",
    "# 替換成要爬取的PTT板網址、頁數、要儲存的檔名\n",
    "main('https://www.ptt.cc/bbs/Bank_Service/index.html', 20, 'ptt_bank_text.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共抓取了102筆資料。\n",
      "\n",
      "第一筆資料：\n",
      "                作者            看板                             標題  \\\n",
      "0  monkkeywom (キラ)  Bank_Service  [情報] 星展digibank首登最高領200＋新舊戶抽獎   \n",
      "\n",
      "                         日期  \\\n",
      "0  Thu Feb  1 20:46:29 2024   \n",
      "\n",
      "                                                  內文 推文數 噓文數 箭頭留言數  \\\n",
      "0  去年底就有看過這活動，好像有名額限制\\n發現到3月都還有，之前沒領過的可以趕快登入看看\\n一...   5   0     0   \n",
      "\n",
      "                                                  連結  \\\n",
      "0  https://www.ptt.cc/bbs/Bank_Service/M.17067915...   \n",
      "\n",
      "                                                留言資訊  \n",
      "0  [{\"type\": \"推\", \"user\": \"yamiyami\", \"content\": ...  \n"
     ]
    }
   ],
   "source": [
    "# 將抓取的資料轉換成df\n",
    "def info(filename):\n",
    "    all_info = pd.read_csv(filename)\n",
    "    return all_info\n",
    "\n",
    "\n",
    "all_info = info('ptt_bank_textk.csv')  # 這裡要輸入檔名\n",
    "\n",
    "print(f'總共抓取了{all_info.shape[0]}筆資料。\\n')\n",
    "print(f'第一筆資料：\\n{all_info.loc[0, :].to_frame().T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "處理後的標題：                       作者            看板                          標題  \\\n",
      "0         monkkeywom (キラ)  Bank_Service    星展digibank首登最高領200＋新舊戶抽獎   \n",
      "1       calmness26 (一顆蘋果)  Bank_Service   中信銀APP連結icashPay新戶最高贈100點   \n",
      "2  jackloutter (Clarkson)  Bank_Service      月初＋農曆年前資料大塞車 郵局系統上午被塞爆   \n",
      "3           eubrgbf (叢雨廚)  Bank_Service            華南能否線上設定「本人」約定帳號   \n",
      "4             kedine (雀榕)  Bank_Service    永豐DAWHO龍年匯好運 換匯抽日幣、switc   \n",
      "\n",
      "                         日期  \\\n",
      "0  Thu Feb  1 20:46:29 2024   \n",
      "1  Fri Feb  2 15:55:45 2024   \n",
      "2  Fri Feb  2 20:27:36 2024   \n",
      "3  Fri Feb  2 21:03:50 2024   \n",
      "4  Fri Feb  2 21:11:30 2024   \n",
      "\n",
      "                                                  內文  推文數  噓文數  箭頭留言數  \\\n",
      "0  去年底就有看過這活動，好像有名額限制\\n發現到3月都還有，之前沒領過的可以趕快登入看看\\n一...    5    0      0   \n",
      "1  中信Home Bank APP銀行存款帳戶連結icash Pay贈OPENPOINT點數\\n...   10    0      5   \n",
      "2  月初＋農曆年前資料大塞車 郵局系統上午被塞爆\\nhttps://www.ctee.com.t...    1    1      2   \n",
      "3  不好意思 需要大家求助\\n小弟有購入一些美金 想換匯成台幣\\n但App顯示沒有設約定帳號\\n...    2    0     24   \n",
      "4  活動內容：龍年匯好運活動不限幣別換匯5000就能抽獎，50000抽switch、Airpod...    2    0      1   \n",
      "\n",
      "                                                  連結  \\\n",
      "0  https://www.ptt.cc/bbs/Bank_Service/M.17067915...   \n",
      "1  https://www.ptt.cc/bbs/Bank_Service/M.17068605...   \n",
      "2  https://www.ptt.cc/bbs/Bank_Service/M.17068768...   \n",
      "3  https://www.ptt.cc/bbs/Bank_Service/M.17068790...   \n",
      "4  https://www.ptt.cc/bbs/Bank_Service/M.17068794...   \n",
      "\n",
      "                                                留言資訊 category  \n",
      "0  [{\"type\": \"推\", \"user\": \"yamiyami\", \"content\": ...       情報  \n",
      "1  [{\"type\": \"推\", \"user\": \"abccbaandy\", \"content\"...       情報  \n",
      "2  [{\"type\": \"→\", \"user\": \"abccbaandy\", \"content\"...       新聞  \n",
      "3  [{\"type\": \"推\", \"user\": \"aljust12\", \"content\": ...       問題  \n",
      "4  [{\"type\": \"推\", \"user\": \"lynnlelia071\", \"conten...       情報  \n"
     ]
    }
   ],
   "source": [
    "# 將標題單獨存成一個column\n",
    "def title_processing(all_info):\n",
    "    all_info['category'] = all_info['標題'].apply(lambda x: x.split(']')[0])\n",
    "    all_info['category'] = all_info['category'].apply(lambda x: x.replace('[', ''))\n",
    "    all_info['標題'] = all_info['標題'].apply(lambda x: x.split(']')[1])  \n",
    "    return all_info\n",
    "\n",
    "\n",
    "all_info = title_processing(all_info)\n",
    "\n",
    "print(f'處理後的標題：{all_info.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新處理欄位後：\n",
      "          board           author category                      title  \\\n",
      "0  Bank_Service  monkkeywom (キラ)       情報   星展digibank首登最高領200＋新舊戶抽獎   \n",
      "\n",
      "                       date  \\\n",
      "0  Thu Feb  1 20:46:29 2024   \n",
      "\n",
      "                                             content  push  boo  arrow  \\\n",
      "0  去年底就有看過這活動，好像有名額限制\\n發現到3月都還有，之前沒領過的可以趕快登入看看\\n一...     5    0      0   \n",
      "\n",
      "                                        comment_info  \\\n",
      "0  [{\"type\": \"推\", \"user\": \"yamiyami\", \"content\": ...   \n",
      "\n",
      "                                                link  \n",
      "0  https://www.ptt.cc/bbs/Bank_Service/M.17067915...  \n"
     ]
    }
   ],
   "source": [
    "# 將column轉換成英文，重新排序\n",
    "def column_name_processing(dll_info):\n",
    "    all_info = dll_info.rename(columns={ '作者': 'author','看板': 'board','標題': 'title','日期': 'date','內文': 'content',\n",
    "                    '推文數': 'push','噓文數': 'boo','箭頭留言數': 'arrow','連結': 'link','留言資訊': 'comment_info'\n",
    "                    })\n",
    "    \n",
    "    all_info = all_info[['board', 'author', 'category', 'title', 'date', 'content', 'push', 'boo', 'arrow', 'comment_info', 'link']]\n",
    "\n",
    "    return all_info  \n",
    "\n",
    "\n",
    "all_info = column_name_processing(all_info)\n",
    "\n",
    "print(f'重新處理欄位後：\\n{all_info.head(1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     type   commenter                      comment  source_index    date_time  \\\n",
      "0       推    yamiyami                 有拿到首次app的100             0  02/02 01:29   \n",
      "1       推      skye11          之前有領過了 還是推個～抽獎就碰碰運氣             0  02/02 13:40   \n",
      "2       推  autumn0121                        有領過+1             0  02/02 14:22   \n",
      "3       推     bigsara      原本看這活動好像到去年底而已，後來又延長到3月             0  02/02 17:42   \n",
      "4       推  pippen2002            首次登入app?? 誰還0登入過?             0  02/02 20:51   \n",
      "...   ...         ...                          ...           ...          ...   \n",
      "3960    →      TZUYIC  想要盜刷也沒錢可以授權，0元的話連綁定授權都不會過，我           101  01/11 19:40   \n",
      "3961    →      TZUYIC                       有試過。XD           101  01/11 19:40   \n",
      "3962    →      TZUYIC  真的要提/轉或要用那張卡消費之前，再轉帳進來就可以了。           101  01/11 19:41   \n",
      "3963    →    qqplusqq               這也是一個方式，避免被盜刷～           101  01/12 00:21   \n",
      "3964    →  pippen2002                        推高手!!           101  01/14 20:33   \n",
      "\n",
      "     ip  \n",
      "0        \n",
      "1        \n",
      "2        \n",
      "3        \n",
      "4        \n",
      "...  ..  \n",
      "3960     \n",
      "3961     \n",
      "3962     \n",
      "3963     \n",
      "3964     \n",
      "\n",
      "[3965 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 將所有留言取出，另外存成df\n",
    "def comment_processing(all_info):\n",
    "\n",
    "    # 從所有的資料集取出留言，存成df\n",
    "    all_comments = pd.DataFrame()\n",
    "    for i in all_info.index:\n",
    "        comments = json.loads(all_info.loc[i, 'comment_info'])\n",
    "        comments_df = pd.DataFrame(comments)\n",
    "        comments_df['source_index'] = i\n",
    "        all_comments = pd.concat([all_comments, comments_df], ignore_index=True)\n",
    "\n",
    "    # 重新命名留言的column，以免和原本的資料集搞混\n",
    "    all_comments.rename(columns={'user': 'commenter', 'content': 'comment'}, inplace=True)\n",
    "\n",
    "    # 將留言的ip和datetime分開\n",
    "    all_comments['date_time'] = all_comments['ipdatetime'].apply(lambda x: x[-11:])\n",
    "    all_comments['ip'] = all_comments['ipdatetime'].apply(lambda x: x[:-12])\n",
    "    all_comments = all_comments.drop(['ipdatetime'], axis=1)\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "\n",
    "all_comments = comment_processing(all_info)\n",
    "\n",
    "print(f'{all_comments}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將結果存成csv檔\n",
    "def save_to_csv(all_info, all_comments):\n",
    "    all_info.to_csv('all_info.csv', index=False, encoding='utf-8-sig')\n",
    "    all_comments.to_csv('all_comments.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "save_to_csv(all_info, all_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
